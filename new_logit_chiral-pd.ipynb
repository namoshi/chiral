{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "new_logit_chiral.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/chiral/blob/master/new_logit_chiral-pd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02NGBqF-MlzH",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression for Chiral/Achiral Classification  (New Data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIZUFWNAMlzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "255224ad-b20c-4a85-dc4b-954fc76e4b8a"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "#import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtiivk9MlzP",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2b2283f-c311-44ee-df1e-b74fe5a8dbe7"
      },
      "source": [
        "# Read data from file (2atom-chiral.csv)\n",
        "with open('2atoms-chiral.csv', 'r') as csvfile:\n",
        "    dataReader = csv.reader(csvfile, delimiter=',')\n",
        "    # Skip Header\n",
        "    next(dataReader)\n",
        "    chiral_data = []\n",
        "    count = 0\n",
        "    for row in dataReader:\n",
        "        # print(\"line Num = %02d\" % count)\n",
        "        chiral_data.append([row[7], row[12]])\n",
        "        count += 1\n",
        "\n",
        "\n",
        "#X_chiral = np.asarray(chiral_data[1:])\n",
        "X_chiral = np.asarray(chiral_data)\n",
        "X_chiral = X_chiral.astype(np.float)\n",
        "\n",
        "print('len=', len(X_chiral))\n",
        "\n",
        "y_chiral = np.ones((len(X_chiral)))\n",
        "\n",
        "print(X_chiral)\n",
        "print(y_chiral)\n",
        "\n",
        "\n",
        "# Read data from file (2atom-achiral.csv)\n",
        "with open('2atoms-achiral.csv', 'r') as csvfile:\n",
        "    dataReader = csv.reader(csvfile, delimiter=',')\n",
        "    # Skip Header\n",
        "    next(dataReader)\n",
        "    chiral_data = []\n",
        "    count = 0\n",
        "    for row in dataReader:\n",
        "        #    print \"line Num = %02d\" % count\n",
        "        chiral_data.append([row[7], row[12]])\n",
        "        count += 1\n",
        "\n",
        "\n",
        "#X_achiral = np.asarray(chiral_data[1:])\n",
        "X_achiral = np.asarray(chiral_data)\n",
        "X_achiral = X_achiral.astype(np.float)\n",
        "\n",
        "print('len=', len(X_achiral))\n",
        "\n",
        "y_achiral = np.zeros((len(X_achiral)))\n",
        "\n",
        "print(X_achiral)\n",
        "print(y_achiral)\n",
        "\n",
        "X = np.concatenate((X_chiral, X_achiral), axis=0)\n",
        "y = np.concatenate((y_chiral, y_achiral), axis=0)\n",
        "print('X=', X)\n",
        "print('y=', y)\n",
        "\n",
        "# Binary representation of the variables\n",
        "a_categorical = np_utils.to_categorical(X[:,0]-1)\n",
        "print('A=', a_categorical)\n",
        "\n",
        "\n",
        "b_categorical = np_utils.to_categorical(X[:,1]-1)\n",
        "\n",
        "print('B=', b_categorical)\n",
        "\n",
        "#print(np.sum(b_categorical, axis=0))\n",
        "\n",
        "# concatenate a_categorical and b_categorical\n",
        "abxy = np.c_[a_categorical, b_categorical]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,3]/X[:,2]]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,2:3]]\n",
        "\n",
        "print('AB=', abxy)\n",
        "\n",
        "#print(np.sum(abxy, axis=0))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len= 555\n",
            "[[  2.  15.]\n",
            " [ 14.  16.]\n",
            " [  8.  16.]\n",
            " ..., \n",
            " [  9.  12.]\n",
            " [  9.  12.]\n",
            " [  3.  16.]]\n",
            "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            "len= 10811\n",
            "[[ 16.  17.]\n",
            " [  2.  15.]\n",
            " [  5.  16.]\n",
            " ..., \n",
            " [  1.  14.]\n",
            " [  1.  14.]\n",
            " [  1.  14.]]\n",
            "[ 0.  0.  0. ...,  0.  0.  0.]\n",
            "X= [[  2.  15.]\n",
            " [ 14.  16.]\n",
            " [  8.  16.]\n",
            " ..., \n",
            " [  1.  14.]\n",
            " [  1.  14.]\n",
            " [  1.  14.]]\n",
            "y= [ 1.  1.  1. ...,  0.  0.  0.]\n",
            "A= [[ 0.  1.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " ..., \n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
            "B= [[ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  1.  0.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
            "AB= [[ 0.  1.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  1.  0.  0.]\n",
            " ..., \n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKgDLc46MlzU",
        "colab_type": "text"
      },
      "source": [
        "全サンプルにロジスティック回帰を適用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w8ulKbuMlzV",
        "colab_type": "code",
        "colab": {},
        "outputId": "268aa072-a585-4f7d-910c-f88d5ca640bf"
      },
      "source": [
        "# logistic regression for categorical A and B\n",
        "logreg = linear_model.LogisticRegression()\n",
        "\n",
        "logreg.fit(abxy, y)\n",
        "\n",
        "pred = logreg.predict(abxy)\n",
        "\n",
        "#print('pred=', pred)\n",
        "\n",
        "score = logreg.score(abxy, y)\n",
        "\n",
        "print('Logistic Regression for Categorical Data (using all samples)')\n",
        "print('Recognition Rates = ', score)\n",
        "\n",
        "coeffs = logreg.coef_[0]\n",
        "intercept = logreg.intercept_[0]\n",
        "\n",
        "#print('Coeffs is ', coeffs)\n",
        "print('Intercept is ', intercept)\n",
        "print('Coeffs are')\n",
        "for i in range(0, len(coeffs)):\n",
        "    print(coeffs[i])\n",
        "\n",
        "ix = range(0, len(coeffs))\n",
        "plt.bar(ix, coeffs)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression for Categorical Data (using all samples)\n",
            "Recognition Rates =  0.951170156607\n",
            "Intercept is  -2.97057693554\n",
            "Coeffs are\n",
            "-0.383036728224\n",
            "-0.570135850075\n",
            "-1.29241940908\n",
            "-0.874893632044\n",
            "-0.200874742229\n",
            "-0.488506230148\n",
            "0.15238588092\n",
            "0.348983095009\n",
            "-0.168268243013\n",
            "0.0646202916474\n",
            "-0.403997919016\n",
            "0.446690519009\n",
            "0.0192621303339\n",
            "-0.0352759382692\n",
            "-0.0871559402235\n",
            "0.56125366636\n",
            "-0.284060295835\n",
            "0.224852409323\n",
            "0.761292602356\n",
            "-0.354695885565\n",
            "-1.67776121244\n",
            "-1.40712060077\n",
            "-1.79255110252\n",
            "-0.41746325652\n",
            "-0.135282580008\n",
            "-0.590122016423\n",
            "-0.462576488363\n",
            "-0.257015690992\n",
            "-0.0587707732703\n",
            "0.369520686361\n",
            "0.176933613459\n",
            "0.909489079179\n",
            "0.786347736987\n",
            "0.887956256277\n",
            "0.348069902257\n",
            "-0.0568272055676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEmNMgAkqVH/C5ZIwdwsnPb4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11a2cc630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGtNaDb4Mlzb",
        "colab_type": "text"
      },
      "source": [
        "サンプル数がアンバランスなので，achiralのサンプルから１０００サンプルをランダムに選択して，ロジスティック回帰を適用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVOE3Z7qMlzc",
        "colab_type": "code",
        "colab": {},
        "outputId": "78a11c5a-530b-48c7-b86e-21d616ceed48"
      },
      "source": [
        "#===========================================================================\n",
        "#### Reduce the number of achiral samples\n",
        "# 1000 samples are randomly selected\n",
        "sind = np.random.permutation(range(len(X_achiral)))\n",
        "sind = sind[:1000]\n",
        "\n",
        "X = np.concatenate((X_chiral, X_achiral[sind]), axis=0)\n",
        "y = np.concatenate((y_chiral, y_achiral[sind]), axis=0)\n",
        "print('X=', X)\n",
        "print('y=', y)\n",
        "\n",
        "# Binary representation of the variables\n",
        "a_categorical = np_utils.to_categorical(X[:,0]-1)\n",
        "print('A=', a_categorical)\n",
        "\n",
        "print(np.sum(a_categorical, axis=0))\n",
        "\n",
        "b_categorical = np_utils.to_categorical(X[:,1]-1)\n",
        "\n",
        "print('B=', b_categorical)\n",
        "\n",
        "print(np.sum(b_categorical, axis=0))\n",
        "\n",
        "# concatenate a_categorical and b_categorical\n",
        "abxy = np.c_[a_categorical, b_categorical]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,3]/X[:,2]]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,2:3]]\n",
        "\n",
        "print('AB=', abxy)\n",
        "\n",
        "#print(np.sum(abxy, axis=0))\n",
        "\n",
        "# logistic regression for categorical A and B\n",
        "logreg = linear_model.LogisticRegression()\n",
        "\n",
        "logreg.fit(abxy, y)\n",
        "\n",
        "pred = logreg.predict(abxy)\n",
        "\n",
        "#print('pred=', pred)\n",
        "\n",
        "score = logreg.score(abxy, y)\n",
        "\n",
        "print('Logistic Regression for Categorical Data (1000 achiral samples are randomly selected)')\n",
        "print('Recognition Rates = ', score)\n",
        "\n",
        "coeffs = logreg.coef_[0]\n",
        "intercept = logreg.intercept_[0]\n",
        "\n",
        "#print('Coeffs is ', coeffs)\n",
        "print('Intercept is ', intercept)\n",
        "print('Coeffs are')\n",
        "for i in range(0, len(coeffs)):\n",
        "    print(coeffs[i])\n",
        "\n",
        "ix = range(0, len(coeffs))\n",
        "plt.bar(ix, coeffs)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X= [[  2.  15.]\n",
            " [ 14.  16.]\n",
            " [  8.  16.]\n",
            " ..., \n",
            " [  9.   9.]\n",
            " [  3.  13.]\n",
            " [  9.  14.]]\n",
            "y= [ 1.  1.  1. ...,  0.  0.  0.]\n",
            "A= [[ 0.  1.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  1. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
            "[ 109.  113.  361.   77.  106.   64.   46.  109.   72.   98.   72.   56.\n",
            "  117.   81.   54.   17.    2.    1.]\n",
            "B= [[ 0.  0.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
            "[  64.   31.  118.   27.   25.   14.   16.   25.   37.   69.   21.   57.\n",
            "  126.  251.  192.  369.  113.]\n",
            "AB= [[ 0.  1.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  1. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
            "Logistic Regression for Categorical Data (1000 achiral samples are randomly selected)\n",
            "Recognition Rates =  0.686816720257\n",
            "Intercept is  -0.826620158423\n",
            "Coeffs are\n",
            "-0.511043804295\n",
            "-0.574320210492\n",
            "-1.13439415707\n",
            "-0.689652451516\n",
            "-0.261597227896\n",
            "-0.502705798355\n",
            "0.783751783109\n",
            "0.405422487652\n",
            "0.324745618752\n",
            "0.135325915135\n",
            "-0.221204596944\n",
            "0.473178792523\n",
            "0.173382498336\n",
            "-0.158101594711\n",
            "-0.181888024133\n",
            "0.719551230117\n",
            "0.0431372331543\n",
            "0.349792148208\n",
            "0.83607994028\n",
            "-0.377619488666\n",
            "-1.64434667228\n",
            "-1.22890264448\n",
            "-1.78495875733\n",
            "-0.334129003399\n",
            "0.0664686284439\n",
            "-0.329691470911\n",
            "-0.519932590384\n",
            "-0.0291523296177\n",
            "0.251597687218\n",
            "0.46928641528\n",
            "0.299778234405\n",
            "0.932876092754\n",
            "0.856210221014\n",
            "1.09009838938\n",
            "0.619717189872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11cb5a630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFozqACvMlzg",
        "colab_type": "text"
      },
      "source": [
        "サンプル数がアンバランスなので，achiralのサンプルから２０００サンプルをランダムに選択して，ロジスティック回帰を適用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304OYAiFMlzh",
        "colab_type": "code",
        "colab": {},
        "outputId": "8a9f9670-bc42-418e-d693-2ee5ce9f6e97"
      },
      "source": [
        "#==============================================================================\n",
        "# 2000 samples are randomly selected\n",
        "sind = np.random.permutation(range(len(X_achiral)))\n",
        "sind = sind[:2000]\n",
        "\n",
        "X = np.concatenate((X_chiral, X_achiral[sind]), axis=0)\n",
        "y = np.concatenate((y_chiral, y_achiral[sind]), axis=0)\n",
        "print('X=', X)\n",
        "print('y=', y)\n",
        "\n",
        "# Binary representation of the variables\n",
        "a_categorical = np_utils.to_categorical(X[:,0]-1)\n",
        "print('A=', a_categorical)\n",
        "\n",
        "\n",
        "b_categorical = np_utils.to_categorical(X[:,1]-1)\n",
        "\n",
        "print('B=', b_categorical)\n",
        "\n",
        "#print(np.sum(b_categorical, axis=0))\n",
        "\n",
        "# concatenate a_categorical and b_categorical\n",
        "abxy = np.c_[a_categorical, b_categorical]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,3]/X[:,2]]\n",
        "#abxy = np.c_[np.c_[a_categorical, b_categorical[:,8:]], X[:,2:3]]\n",
        "\n",
        "print('AB=', abxy)\n",
        "\n",
        "#print(np.sum(abxy, axis=0))\n",
        "\n",
        "# logistic regression for categorical A and B\n",
        "logreg = linear_model.LogisticRegression()\n",
        "\n",
        "logreg.fit(abxy, y)\n",
        "\n",
        "pred = logreg.predict(abxy)\n",
        "\n",
        "#print('pred=', pred)\n",
        "\n",
        "score = logreg.score(abxy, y)\n",
        "\n",
        "print('Logistic Regression for Categorical Data (2000 achiral samples are randomly selected)')\n",
        "print('Recognition Rates = ', score)\n",
        "\n",
        "coeffs = logreg.coef_[0]\n",
        "intercept = logreg.intercept_[0]\n",
        "\n",
        "#print('Coeffs is ', coeffs)\n",
        "print('Intercept is ', intercept)\n",
        "print('Coeffs are')\n",
        "for i in range(0, len(coeffs)):\n",
        "    print(coeffs[i])\n",
        "\n",
        "ix = range(0, len(coeffs))\n",
        "plt.bar(ix, coeffs)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X= [[  2.  15.]\n",
            " [ 14.  16.]\n",
            " [  8.  16.]\n",
            " ..., \n",
            " [  3.  13.]\n",
            " [ 11.   3.]\n",
            " [  5.  16.]]\n",
            "y= [ 1.  1.  1. ...,  0.  0.  0.]\n",
            "A= [[ 0.  1.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " ..., \n",
            " [ 0.  0.  1. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
            "B= [[ 0.  0.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  1. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
            "AB= [[ 0.  1.  0. ...,  1.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]\n",
            " ..., \n",
            " [ 0.  0.  1. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
            "Logistic Regression for Categorical Data (2000 achiral samples are randomly selected)\n",
            "Recognition Rates =  0.782778864971\n",
            "Intercept is  -1.48159766422\n",
            "Coeffs are\n",
            "-0.32676497125\n",
            "-0.438118979998\n",
            "-1.17868291532\n",
            "-0.839270288029\n",
            "-0.0927972319539\n",
            "-0.626763791789\n",
            "0.0962351414824\n",
            "0.478003251653\n",
            "-0.0444050962593\n",
            "0.302230837746\n",
            "-0.272812049952\n",
            "0.470148339918\n",
            "0.151626273247\n",
            "-0.0120466362104\n",
            "0.182228995529\n",
            "0.598265881587\n",
            "0.0427859679249\n",
            "0.0285396074573\n",
            "0.793580843195\n",
            "-0.211251571167\n",
            "-1.58245533325\n",
            "-1.20261250255\n",
            "-1.84696817978\n",
            "-0.540275300405\n",
            "0.00690044292149\n",
            "-0.440040027959\n",
            "-0.265000487442\n",
            "-0.0651486147556\n",
            "-0.135521680039\n",
            "0.236187393542\n",
            "0.269635659749\n",
            "1.0006784171\n",
            "0.946805734281\n",
            "0.974955401061\n",
            "0.578932141279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x11cd785f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a11gZMi7Mlzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}